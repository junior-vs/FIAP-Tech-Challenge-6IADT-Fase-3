#!/usr/bin/env python3
"""
Assistente M√©dico Virtual - Interface de Chat Interativa

Este script fornece uma interface de linha de comando para um assistente de IA de suporte
a decis√µes m√©dicas que usa RAG (Retrieval-Augmented Generation) com bases de conhecimento
m√©dico para responder perguntas relacionadas √† sa√∫de de forma segura e precisa.

O assistente √© constru√≠do usando:
- LangChain: Para orquestra√ß√£o de fluxos de trabalho de IA
- LangGraph: Para cria√ß√£o de m√°quinas de estado e grafos de decis√£o
- Google Gemini: Como o modelo de linguagem principal
- ChromaDB: Para armazenamento e recupera√ß√£o de documentos baseada em vetores
"""

import sys
from pathlib import Path
from typing import Any, Dict

# === CONFIGURA√á√ÉO DO PROJETO ===
# IMPORTANTE: Configurar o caminho ANTES de qualquer importa√ß√£o de m√≥dulos src
# Adiciona o diret√≥rio raiz do projeto ao caminho de busca de m√≥dulos do Python
# Isso permite importar m√≥dulos usando importa√ß√µes absolutas como 'src.module'
project_root = Path(__file__).parent.parent.resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# === IMPORTA√á√ïES ===
# Agora podemos importar os m√≥dulos src ap√≥s configurar o caminho
from loguru import logger

from src.domain.state import AgentState
from src.use_cases.graph import GraphBuilder
from src.utils.logging import setup_logging

# === CONSTANTES DE CONFIGURA√á√ÉO ===
# Constantes de exibi√ß√£o da aplica√ß√£o para melhor manutenibilidade
APP_NAME = "Assistente M√©dico Virtual"
APP_DESCRIPTION = "Sistema de suporte a decis√µes cl√≠nicas baseado em protocolos internos"
TECH_STACK = "Desenvolvido com LangChain + LangGraph + Google Gemini"
DIVIDER_LENGTH = 70

# Comandos de sa√≠da que os usu√°rios podem digitar para encerrar a aplica√ß√£o
EXIT_COMMANDS = ("sair", "exit", "quit", "q")


def create_initial_agent_state(user_question: str) -> AgentState:
    """
    Cria o estado inicial para o pipeline de processamento do agente de IA.
    
    Esta fun√ß√£o configura a estrutura de dados que fluir√° atrav√©s
    de todo o fluxo de trabalho RAG (Retrieval-Augmented Generation).
    
    Args:
        user_question (str): A pergunta m√©dica do usu√°rio
        
    Returns:
        AgentState: Dicion√°rio de estado inicial com todos os campos necess√°rios
        
    Por que isso √© importante:
    - O AgentState atua como uma mem√≥ria compartilhada entre as etapas de processamento
    - Cada etapa do pipeline pode ler e modificar este estado
    - Isso garante consist√™ncia de dados em todo o fluxo de trabalho
    """
    return {
        # Entrada principal do usu√°rio
        "medical_question": user_question,
        
        # Flags de seguran√ßa e valida√ß√£o
        "is_safe": True,          # Se a pergunta passou pelas verifica√ß√µes de seguran√ßa
        "is_valid": True,         # Se a resposta foi validada
        "risk_level": "low",      # N√≠vel de avalia√ß√£o de risco
        
        # Resultados da recupera√ß√£o de documentos
        "documents": [],          # Protocolos m√©dicos recuperados da base de dados
        
        # Gera√ß√£o de resposta da IA
        "generation": "",         # A resposta gerada pela IA
        "hallucination_check": "", # Valida√ß√£o contra documentos fonte
        
        # Contexto e hist√≥rico
        "context_data": "",       # Contexto adicional se necess√°rio
        "chat_history": [],       # Turnos de conversa anteriores
        "loop_count": 0,         # Contador de itera√ß√µes de processamento
    }


def display_welcome_message() -> None:
    """
    Exibe a tela de boas-vindas da aplica√ß√£o e instru√ß√µes.
    
    Isso cria uma interface profissional com tema m√©dico que:
    - Identifica claramente o prop√≥sito da aplica√ß√£o
    - Mostra a pilha de tecnologia para transpar√™ncia
    - Fornece instru√ß√µes claras de uso
    """
    print("\n" + "=" * DIVIDER_LENGTH)
    print(f"üè• {APP_NAME}")
    print("=" * DIVIDER_LENGTH)
    print(f"\nüìã {APP_DESCRIPTION}")
    print(f"{TECH_STACK}\n")


def display_chat_instructions() -> None:
    """Exibe instru√ß√µes para a sess√£o de chat interativa."""
    print("-" * DIVIDER_LENGTH)
    print("üí¨ Digite suas d√∫vidas cl√≠nicas (ou 'sair' para encerrar)\n")


def get_user_input() -> str:
    """
    Obt√©m e valida a entrada do usu√°rio da linha de comando.
    
    Returns:
        str: A entrada do usu√°rio, sem espa√ßos em branco
        
    Por que removemos espa√ßos em branco:
    - Previne o processamento de entradas vazias ou apenas com espa√ßos
    - Garante formato consistente de entrada para processamento posterior
    """
    return input("üë®‚Äç‚öïÔ∏è  Voc√™: ").strip()


def should_exit_application(user_input: str) -> bool:
    """
    Verifica se o usu√°rio quer sair da aplica√ß√£o.
    
    Args:
        user_input (str): A entrada do usu√°rio para verificar
        
    Returns:
        bool: True se o usu√°rio quer sair, False caso contr√°rio
        
    Esta fun√ß√£o fornece flexibilidade aceitando m√∫ltiplos comandos de sa√≠da
    em diferentes idiomas (Portugu√™s, Ingl√™s) para melhor experi√™ncia do usu√°rio.
    """
    return user_input.lower() in EXIT_COMMANDS


def is_empty_input(user_input: str) -> bool:
    """
    Verifica se o usu√°rio forneceu entrada vazia.
    
    Args:
        user_input (str): A entrada do usu√°rio para validar
        
    Returns:
        bool: True se a entrada estiver vazia, False caso contr√°rio
    """
    return not user_input


def process_medical_question(app, user_question: str) -> Dict[str, Any]:
    """
    Processa uma pergunta m√©dica atrav√©s do pipeline de IA.
    
    Args:
        app: A aplica√ß√£o LangGraph compilada
        user_question (str): A pergunta m√©dica para processar
        
    Returns:
        Dict[str, Any]: O estado final ap√≥s processamento atrav√©s de todas as etapas do pipeline
        
    Etapas do Pipeline:
    1. Guardrails: Verifica se a pergunta √© segura e medicamente relevante
    2. Recupera√ß√£o: Encontra documentos relevantes da base de conhecimento
    3. Classifica√ß√£o: Filtra documentos por relev√¢ncia
    4. Gera√ß√£o: Cria resposta da IA baseada nos documentos recuperados
    5. Valida√ß√£o: Verifica resposta por precis√£o e alucina√ß√µes
    """
    logger.debug(f"Processando pergunta: {user_question[:60]}...")
    print("\nüîç Processando pergunta...\n")
    
    # Cria estado inicial para o pipeline de processamento
    initial_state = create_initial_agent_state(user_question)
    
    # Executa o pipeline RAG completo
    # Isso passar√° o estado atrav√©s de todos os n√≥s de processamento em sequ√™ncia
    # O modelo usa temperatura 0.0 para respostas determin√≠sticas e consistentes
    final_state = app.invoke(initial_state)
    
    return final_state


def display_response(result: Dict[str, Any]) -> None:
    """
    Exibe a resposta da IA para o usu√°rio com formata√ß√£o apropriada.
    
    Args:
        result (Dict[str, Any]): O estado final do pipeline de IA
        
    Esta fun√ß√£o trata diferentes cen√°rios de resposta:
    - Perguntas inseguras (rejeitadas pelos guardrails)
    - Respostas inv√°lidas (falharam na valida√ß√£o)
    - Respostas bem-sucedidas com cita√ß√µes de fonte
    """
    # Verifica se a pergunta foi rejeitada pelos guardrails de seguran√ßa
    # Os guardrails validam se a pergunta √© medicamente relevante e n√£o cont√©m PII
    if result.get("is_safe") is False:
        logger.warning("Pergunta rejeitada pelos guardrails")
        fallback_message = "Pergunta fora do escopo m√©dico."
        response = result.get("generation", fallback_message)
        print(f"‚ö†Ô∏è  Assistente: {response}\n")
        return
    
    # Verifica se a resposta falhou na valida√ß√£o (ex: alucina√ß√£o detectada)
    if result.get("is_valid") is False:
        logger.warning("Resposta rejeitada devido a falha na valida√ß√£o")
        fallback_message = "N√£o foi poss√≠vel gerar uma resposta confi√°vel."
        response = result.get("generation", fallback_message)
        print(f"‚ö†Ô∏è  Assistente: {response}\n")
        return
    
    # Exibe resposta bem-sucedida
    logger.info("‚úÖ Resposta gerada com sucesso")
    fallback_message = "Desculpe, n√£o consegui processar a pergunta."
    response = result.get("generation", fallback_message)
    print(f"ü§ñ Assistente: {response}\n")


def display_sources(result: Dict[str, Any]) -> None:
    """
    Exibe os protocolos m√©dicos/fontes consultados para a resposta.
    
    Args:
        result (Dict[str, Any]): O estado final contendo documentos recuperados
        
    Esta fun√ß√£o fornece transpar√™ncia mostrando aos usu√°rios quais
    protocolos m√©dicos foram consultados, permitindo verificar as fontes de informa√ß√£o.
    """
    documents = result.get("documents", [])
    if not documents:
        return
    
    print("üìö Protocolos consultados:")
    # Limita √†s primeiras 3 fontes para manter a exibi√ß√£o limpa
    for document in documents[:3]:
        source_name = document.metadata.get("source", "Fonte desconhecida")
        print(f"   ‚Ä¢ {source_name}")
    
    # Mostra contagem se mais fontes foram usadas
    if len(documents) > 3:
        remaining_count = len(documents) - 3
        print(f"   ... e mais {remaining_count} protocolos")
    
    print()  # Adiciona espa√ßamento ap√≥s as fontes


def handle_chat_loop(app) -> None:
    """
    Gerencia o loop principal de chat interativo com o usu√°rio.
    
    Args:
        app: A aplica√ß√£o LangGraph compilada para processar perguntas
        
    Esta fun√ß√£o gerencia todo o ciclo de vida da intera√ß√£o do usu√°rio:
    - Obtendo entrada do usu√°rio
    - Processando perguntas m√©dicas
    - Exibindo respostas e fontes
    - Tratando erros graciosamente
    - Gerenciando sa√≠da da aplica√ß√£o
    """
    display_chat_instructions()
    
    while True:
        try:
            # Obt√©m entrada do usu√°rio
            user_input = get_user_input()
            
            # Verifica comandos de sa√≠da
            if should_exit_application(user_input):
                print("\nüëã Encerrando assistente m√©dico. At√© logo!\n")
                logger.info("üõë Usu√°rio encerrou a sess√£o")
                break
            
            # Valida se a entrada n√£o est√° vazia
            if is_empty_input(user_input):
                print("‚ö†Ô∏è  Digite uma pergunta v√°lida\n")
                continue
            
            # Processa a pergunta m√©dica atrav√©s do pipeline de IA
            result = process_medical_question(app, user_input)
            
            # Exibe resposta e fontes para o usu√°rio
            display_response(result)
            display_sources(result)
            
        except KeyboardInterrupt:
            # Trata Ctrl+C graciosamente
            print("\n\nüëã Interrup√ß√£o do usu√°rio. Encerrando...\n")
            logger.info("üõë Interrompido por Ctrl+C")
            break
            
        except Exception as error:
            # Trata erros inesperados durante o processamento de perguntas
            logger.error(f"‚ùå Erro ao processar pergunta: {error}", exc_info=True)
            print(f"‚ùå Erro t√©cnico: {error}\n")


def initialize_ai_system() -> object:
    """
    Inicializa o sistema de IA construindo o grafo de processamento.
    
    Returns:
        object: A aplica√ß√£o LangGraph compilada pronta para uso
        
    Raises:
        Exception: Se a inicializa√ß√£o falhar
        
    Esta fun√ß√£o configura todo o pipeline de IA incluindo:
    - Carregamento de modelos de linguagem
    - Conex√£o com base de dados vetorial
    - Constru√ß√£o do grafo de processamento
    - Compila√ß√£o do fluxo de trabalho
    """
    logger.info("üî® Inicializando grafo de orquestra√ß√£o...")
    
    # Cria e configura o construtor do grafo
    graph_builder = GraphBuilder()
    
    # Constr√≥i e compila o grafo de processamento
    # Isso cria o fluxo de trabalho que processar√° perguntas dos usu√°rios
    compiled_app = graph_builder.build()
    
    logger.info("‚úÖ Grafo inicializado com sucesso\n")
    return compiled_app


def main() -> None:
    """
    Ponto de entrada principal da aplica√ß√£o.
    
    Esta fun√ß√£o orquestra todo o ciclo de vida da aplica√ß√£o:
    1. Configura sistema de logging
    2. Exibe mensagem de boas-vindas
    3. Inicializa componentes do sistema de IA
    4. Inicia loop de chat interativo
    5. Trata quaisquer erros cr√≠ticos
    
    A fun√ß√£o √© projetada com tratamento adequado de erros para garantir
    uma boa experi√™ncia do usu√°rio mesmo quando algo d√° errado.
    """
    # Inicializa sistema de logging para depura√ß√£o e monitoramento
    setup_logging(level="INFO")
    
    # Exibe mensagem de boas-vindas e informa√ß√µes da aplica√ß√£o
    display_welcome_message()
    
    try:
        # Inicializa o sistema de IA (LLM, base vetorial, grafo de processamento)
        ai_app = initialize_ai_system()
        
        # Inicia a sess√£o de chat interativa com o usu√°rio
        handle_chat_loop(ai_app)
        
    except Exception as critical_error:
        # Trata erros cr√≠ticos de inicializa√ß√£o
        logger.critical(f"‚ùå Erro cr√≠tico de inicializa√ß√£o: {critical_error}", exc_info=True)
        print(f"\n‚ùå ERRO CR√çTICO: {critical_error}")
        print("Verifique os logs em logs/assistente-medico-errors.log para mais detalhes.\n")
        sys.exit(1)


# === PONTO DE ENTRADA DA APLICA√á√ÉO ===
# Isso garante que main() s√≥ execute quando o script for executado diretamente,
# n√£o quando importado como m√≥dulo
if __name__ == "__main__":
    main()