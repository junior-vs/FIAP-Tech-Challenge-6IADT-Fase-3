"""
M√≥dulo: src/use_cases/nodes.py
Descri√ß√£o: Implementa√ß√£o dos n√≥s do grafo (Passos da execu√ß√£o).
Motivo da altera√ß√£o: 
- Altera√ß√£o dos Prompts para persona "Assistente M√©dico".
- Uso das chaves do novo AgentState (medical_question, is_safe).
- Inclus√£o de instru√ß√µes de seguran√ßa (n√£o prescrever sem valida√ß√£o).
"""

import logging
import re
from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.domain.state import AgentState
from src.domain.guardrails import GuardrailsGrade, HallucinationGrade, DocumentGrade
from src.infrastructure.llm_factory import LLMFactory
from src.infrastructure.vector_store import VectorStoreRepository
from src.utils.logging import logger

logger = logging.getLogger(__name__)

class RAGNodes:
    """
    N√≥s do grafo RAG para processamento de perguntas m√©dicas.
    Implementa valida√ß√£o, recupera√ß√£o, classifica√ß√£o e gera√ß√£o de respostas.
    """
    
    def __init__(self, retriever, llm):
        self.retriever = retriever
        self.llm = llm
        
        # Chain para valida√ß√£o de guardrails com prompt aprimorado
        self.guardrails_prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um classificador especializado em identificar perguntas m√©dicas e cl√≠nicas.

Sua tarefa √© determinar se uma pergunta est√° relacionada ao contexto m√©dico, de sa√∫de ou cl√≠nico.

CRIT√âRIOS PARA PERGUNTAS V√ÅLIDAS:
- Perguntas sobre condi√ß√µes m√©dicas, doen√ßas, sintomas
- Perguntas sobre tratamentos, medicamentos, protocolos cl√≠nicos
- Perguntas sobre anatomia, fisiologia, patologia
- Perguntas sobre diagn√≥sticos, exames, procedimentos
- Perguntas sobre sa√∫de preventiva, cuidados de sa√∫de
- Perguntas sobre especialidades m√©dicas
- Perguntas sobre quest√µes de sa√∫de espec√≠ficas para diferentes popula√ß√µes (idosos, crian√ßas, etc.)

CRIT√âRIOS PARA REJEI√á√ÉO:
- Perguntas sobre assuntos completamente n√£o-m√©dicos (esportes, culin√°ria, tecnologia geral)
- Solicita√ß√µes para atividades ilegais ou perigosas
- Perguntas com conte√∫do ofensivo ou inadequado

IMPORTANTE: 
- A pergunta pode estar em qualquer idioma (portugu√™s, ingl√™s, espanhol, etc.)
- Analise o CONTE√öDO SEM√ÇNTICO, n√£o apenas palavras-chave
- Seja PERMISSIVO para temas relacionados √† sa√∫de
- Em caso de d√∫vida, ACEITE a pergunta

Responda apenas com:
- "v√°lida" se a pergunta est√° relacionada ao contexto m√©dico/sa√∫de
- "inv√°lida" se a pergunta est√° claramente fora do escopo m√©dico"""),
            ("human", "Pergunta: {question}")
        ])
        
        self.guardrails_chain = (
            self.guardrails_prompt 
            | self.llm 
            | StrOutputParser()
        )
        
        # Chain para valida√ß√£o estruturada (backup)
        self.structured_guardrails_prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um auditor de conformidade m√©dica. Analise se a pergunta est√° relacionada ao contexto m√©dico/sa√∫de.

Considere v√°lidas perguntas sobre:
- Condi√ß√µes m√©dicas e doen√ßas
- Tratamentos e medicamentos  
- Sintomas e diagn√≥sticos
- Protocolos cl√≠nicos
- Anatomia e fisiologia
- Sa√∫de preventiva
- Especialidades m√©dicas
- Cuidados de sa√∫de para popula√ß√µes espec√≠ficas

A pergunta pode estar em qualquer idioma. Analise o significado sem√¢ntico.

Responda no formato JSON especificado."""),
            ("human", "Pergunta: {question}")
        ])
        
        self.structured_guardrails_chain = (
            self.structured_guardrails_prompt 
            | self.llm.with_structured_output(GuardrailsGrade)
        )
        
        # Chain para classifica√ß√£o de documentos
        self.grader_prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um classificador que avalia se um documento recuperado √© relevante para uma pergunta m√©dica.

Analise o conte√∫do do documento e determine se ele cont√©m informa√ß√µes √∫teis para responder √† pergunta.

Responda no formato JSON especificado."""),
            ("human", "Pergunta: {question}\n\nDocumento: {document}")
        ])
        
        self.retrieval_grader = (
            self.grader_prompt 
            | self.llm.with_structured_output(DocumentGrade)
        )
        
        # Chain para gera√ß√£o de respostas
        self.rag_prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um assistente m√©dico especializado que fornece informa√ß√µes baseadas em protocolos cl√≠nicos.

INSTRU√á√ïES:
1. Use APENAS as informa√ß√µes dos protocolos fornecidos no contexto
2. Seja preciso e objetivo nas suas respostas
3. Sempre cite a fonte (nome do protocolo) das informa√ß√µes
4. Se a pergunta estiver em outro idioma, responda no mesmo idioma da pergunta
5. Se n√£o houver informa√ß√£o suficiente no contexto, indique claramente

FORMATO DA RESPOSTA:
- Responda de forma clara e estruturada
- Cite as fontes: (Protocolo: nome_do_arquivo.xml)
- Use linguagem profissional mas acess√≠vel

IMPORTANTE: Esta √© uma ferramenta de apoio √† decis√£o m√©dica. Sempre recomende consulta com profissional de sa√∫de para decis√µes cl√≠nicas."""),
            ("human", "Pergunta: {question}\n\nContexto dos protocolos:\n{context}")
        ])
        
        self.rag_chain = self.rag_prompt | self.llm | StrOutputParser()
        
        # Chain para detec√ß√£o de alucina√ß√µes
        self.hallucination_prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um verificador que determina se uma resposta do LLM est√° baseada nos documentos fornecidos.

Analise se a resposta cont√©m APENAS informa√ß√µes presentes nos documentos ou se h√° conte√∫do adicional n√£o fundamentado.

Responda no formato JSON especificado com:
- is_grounded: "sim" se a resposta est√° totalmente baseada nos documentos, "n√£o" se cont√©m informa√ß√µes extras
- confidence: seu n√≠vel de confian√ßa na avalia√ß√£o
- issues: problemas espec√≠ficos encontrados (se houver)"""),
            ("human", "Documentos: {documents}\n\nResposta do LLM: {generation}")
        ])
        
        self.hallucination_grader = (
            self.hallucination_prompt 
            | self.llm.with_structured_output(HallucinationGrade)
        )

    def guardrails(self, state: AgentState) -> AgentState:
        """
        Valida se a pergunta √© apropriada para o contexto m√©dico.
        Implementa verifica√ß√£o de seguran√ßa e relev√¢ncia com an√°lise sem√¢ntica.
        """
        question = state["medical_question"]
        logger.info(f"üõ°Ô∏è Validando pergunta: {question}")
        
        try:
            # Primeira tentativa com chain simples
            try:
                result = self.guardrails_chain.invoke({"question": question})
                result_clean = result.strip().lower()
                
                # An√°lise mais flex√≠vel do resultado
                is_valid = any(term in result_clean for term in ['v√°lida', 'valid', 'sim', 'yes', 'aceita', 'accept'])
                is_invalid = any(term in result_clean for term in ['inv√°lida', 'invalid', 'n√£o', 'no', 'rejeita', 'reject'])
                
                if is_valid and not is_invalid:
                    logger.info("‚úÖ Pergunta aprovada pelos guardrails")
                    return {**state, "is_safe": True, "risk_level": "baixo"}
                elif is_invalid and not is_valid:
                    logger.warning(f"‚ö†Ô∏è Pergunta rejeitada: {result}")
                    return {
                        **state, 
                        "is_safe": False, 
                        "risk_level": "alto",
                        "generation": "Desculpe, mas essa pergunta est√° fora do escopo m√©dico que posso ajudar. Por favor, fa√ßa uma pergunta relacionada √† sa√∫de ou medicina."
                    }
                else:
                    # Resultado amb√≠guo, usar chain estruturada como backup
                    logger.info("üîÑ Resultado amb√≠guo, usando valida√ß√£o estruturada")
                    raise Exception("Resultado amb√≠guo")
                    
            except Exception as e:
                logger.info(f"üîÑ Fallback para valida√ß√£o estruturada: {str(e)}")
                
                # Usar chain estruturada como backup
                structured_result = self.structured_guardrails_chain.invoke({"question": question})
                
                # Verificar se a resposta est√° fundamentada nos documentos
                if hasattr(structured_result, 'is_safe') and structured_result.is_safe == "sim":
                    logger.info("‚úÖ Pergunta aprovada pelos guardrails estruturados")
                    return {
                        **state, 
                        "is_safe": True, 
                        "risk_level": getattr(structured_result, 'risk_level', 'baixo')
                    }
                elif hasattr(structured_result, 'is_safe'):
                    logger.warning("‚ö†Ô∏è Pergunta rejeitada pelos guardrails estruturados")
                    return {
                        **state, 
                        "is_safe": False, 
                        "risk_level": getattr(structured_result, 'risk_level', 'alto'),
                        "generation": "Desculpe, mas essa pergunta est√° fora do escopo m√©dico que posso ajudar. Por favor, fa√ßa uma pergunta relacionada √† sa√∫de ou medicina."
                    }
                else:
                    # Fallback: tentar acessar como dict
                    if isinstance(structured_result, dict) and structured_result.get('is_safe') == "sim":
                        logger.info("‚úÖ Pergunta aprovada pelos guardrails (dict format)")
                        return {
                            **state, 
                            "is_safe": True, 
                            "risk_level": structured_result.get('risk_level', 'baixo')
                        }
                    else:
                        logger.warning("‚ö†Ô∏è Formato de resposta inesperado do validador")
                        return {
                            **state, 
                            "is_safe": False, 
                            "risk_level": "alto",
                            "generation": "Erro na valida√ß√£o da pergunta. Por favor, tente novamente."
                        }
        
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o de guardrails: {str(e)}")
            # Em caso de erro, assumir que √© seguro para n√£o bloquear perguntas m√©dicas v√°lidas
            logger.warning("‚ö†Ô∏è Erro na valida√ß√£o - assumindo pergunta como v√°lida por seguran√ßa")
            return {**state, "is_safe": True, "risk_level": "baixo"}

    def retrieve(self, state: AgentState) -> AgentState:
        """
        Recupera documentos relevantes usando busca sem√¢ntica por vetor.
        """
        question = state["medical_question"]
        logger.info(f"üîç Buscando documentos para: {question}")
        
        try:
            documents = self.retriever.invoke(question)
            logger.info(f"‚úÖ Recuperados {len(documents)} documentos relevantes")
            
            return {**state, "documents": documents}
        
        except Exception as e:
            logger.error(f"‚ùå Erro na recupera√ß√£o de documentos: {str(e)}")
            return {**state, "documents": []}

    def grade_documents(self, state: AgentState) -> AgentState:
        """
        Classifica documentos recuperados quanto √† relev√¢ncia para a pergunta.
        """
        question = state["medical_question"]
        documents = state["documents"]
        
        logger.info(f"üìä Classificando {len(documents)} documentos")
        
        try:
            filtered_docs = []
            
            for doc in documents:
                try:
                    grade = self.retrieval_grader.invoke({
                        "question": question,
                        "document": doc.page_content
                    })
                    
                    # Verificar se o documento √© relevante
                    if hasattr(grade, 'is_relevant') and grade.is_relevant == "sim":
                        filtered_docs.append(doc)
                    elif isinstance(grade, dict) and grade.get('is_relevant') == "sim":
                        filtered_docs.append(doc)
                
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao classificar documento: {str(e)}")
                    # Em caso de erro, manter o documento
                    filtered_docs.append(doc)
            
            logger.info(f"Documentos √∫teis: {len(filtered_docs)}/{len(documents)}")
            
            return {**state, "documents": filtered_docs}
        
        except Exception as e:
            logger.error(f"‚ùå Erro na classifica√ß√£o de documentos: {str(e)}")
            return state

    def generate(self, state: AgentState) -> AgentState:
        """
        Gera resposta baseada nos documentos recuperados e na pergunta.
        """
        question = state["medical_question"]
        documents = state["documents"]
        
        logger.info("ü§ñ Gerando resposta baseada nos protocolos")
        
        try:
            # Preparar contexto dos documentos
            context = "\n\n".join([
                f"Protocolo {i+1}. {doc.metadata.get('source', 'fonte_desconhecida')}: {doc.page_content}"
                for i, doc in enumerate(documents)
            ])
            
            # Gerar resposta
            generation = self.rag_chain.invoke({
                "question": question,
                "context": context
            })
            
            logger.info("‚úÖ Resposta gerada com sucesso")
            
            return {**state, "generation": generation}
        
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de resposta: {str(e)}")
            return {**state, "generation": "Desculpe, ocorreu um erro ao gerar a resposta. Tente novamente."}

    def validate_response(self, state: AgentState) -> AgentState:
        """
        Valida se a resposta gerada √© baseada nos documentos fornecidos.
        Detecta poss√≠veis alucina√ß√µes do modelo.
        """
        generation = state["generation"]
        documents = state["documents"]
        
        logger.info("üîç Validando resposta contra documentos fonte")
        
        try:
            # Preparar contexto dos documentos para verifica√ß√£o
            docs_content = "\n".join([doc.page_content for doc in documents])
            
            # Verificar se h√° alucina√ß√£o usando chain estruturada
            grade = self.hallucination_grader.invoke({
                "documents": docs_content,
                "generation": generation
            })
            
            # Verificar se a resposta est√° fundamentada nos documentos
            if hasattr(grade, 'is_grounded') and grade.is_grounded == "sim":
                logger.info("‚úÖ Resposta validada (baseada em documentos)")
                return {**state, "is_valid": True, "hallucination_check": "approved"}
            elif hasattr(grade, 'is_grounded'):
                logger.warning(f"‚ö†Ô∏è Poss√≠vel alucina√ß√£o detectada: {getattr(grade, 'issues', 'Sem detalhes')}")
                return {**state, "is_valid": False, "hallucination_check": "rejected"}
            else:
                # Fallback: tentar acessar como dict
                if isinstance(grade, dict) and grade.get('is_grounded') == "sim":
                    logger.info("‚úÖ Resposta validada (baseada em documentos)")
                    return {**state, "is_valid": True, "hallucination_check": "approved"}
                else:
                    logger.warning("‚ö†Ô∏è Formato de resposta inesperado do validador")
                    return {**state, "is_valid": False, "hallucination_check": "format_error"}
        
        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o de resposta: {str(e)}")
            # Em caso de erro, assumir que √© v√°lida para n√£o bloquear respostas m√©dicas
            logger.warning("‚ö†Ô∏è Erro na valida√ß√£o - assumindo resposta como v√°lida por seguran√ßa")
            return {**state, "is_valid": True, "hallucination_check": "error_assumed_valid"}